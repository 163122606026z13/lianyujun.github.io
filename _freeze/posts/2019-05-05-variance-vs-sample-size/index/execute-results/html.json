{
  "hash": "b5c739c0d37a053ddea5b35504c88d90",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"When is sample variance is a unreliable estimate of population variance?\"\nsubtitle: \"Empirically showing that show that sample variance has high variance at low sample sizes\"\nauthor: \"Vikram B. Baliga\"\ncategories:\n  - R\n  - variance\n  - sample-size\ndate: 2019-05-05\ntoc: true\nimage: \"variance-small-sample-size.png\"\n---\n\n\nSample variance generally gives an unbiased estimate of the true population\nvariance, but that does not mean it is a reliable estimate of population\nvariance. Here, I show that sample variance itself has high variance at low\nsample sizes.\n\nFirst, we'll create a normally-distributed parent population with a known mean,\nvariance, and sample size. This represents a natural population of something\nwe'd like to study but for sake of time, money, or feasibility, we cannot\nmeasure everything. Our goal is to figure out how reliable smaller samples are\nwith respect to estimates of variance. We'll take increasingly larger samples\nfrom this population and see how sample variance fares.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean = 0\nSD = 20 # Therefore population variance should be ~ 400. \n# We'll set population size low-ish for sake of \n# computational time\npopsize = 1000 \n\nset.seed(123) # reproducibility\n# generate the parent population\npop <- rnorm(popsize, mean, SD)\n\n# Determine the true population variance.\n# It may be different from SD^2, since we are simulating\n# from a normal distribution\nvar(pop)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 393.3836\n```\n\n\n:::\n\n```{.r .cell-code}\n# Now create a sequence from 1 to popsize\n# in increments of 1\nNs <- seq(1, popsize, 1)\n# Within a sample size, we'll create 1000 replicates\n# to help us generalize our findings\nreps = 1000\n\n# The var() function takes n-1 in the denominator to give\n# a less biased estimator of population variance. We also\n# need a function to give the variance if we've got the \n# whole population.\nvar.p <- function(x) {\n  var(x) * (length(x) - 1) / length(x)\n}\n```\n:::\n\n\n## How does sample variance 'behave'?\n\nUsing our sequence of increasing sample size (`Ns`), we'll now create a matrix\nof variances. Each row number will correspond to its sample size. E.g. all\nvalues in row \\[50,\\] are variances from random samples of n = 50 taken from the\nparent population. Therefore, samples in row \\[1000,\\] should be identical and\nequal to the parent population's variance, since we are drawing all 1000 samples\nfrom the parent population.\n\nThis process is repeated 1000 (`reps`) times for each sample size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This may take some time.\nmymat = matrix(nrow = length(Ns), ncol = reps)\nfor (i in 1:dim(mymat)[1])\n{\n  for (j in 1:dim(mymat)[2])\n  {\n    mymat[i, j] = var(sample(pop, Ns[i]))\n  }\n}\nrownames(mymat) <- seq(1, length(Ns))\n\n# By definition, all the values in row [1,] will be \"NA\", \n# since variance cannot be computed for N = 1. \n# So we'll just remove the row.\nmymat[-1, ] -> varmat \n```\n:::\n\n\nIt's always good to visualize data. We'll first plot these raw estimates of\nvariance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sample size will be on the x-axis\n# and sample variance will be on the y.\n# For a given sample size, 1000 reps were performed.\nplot(\n  rep(2, ncol(varmat)),\n  mymat[2, ],\n  ylim = c(0, max(varmat)),\n  xlim = c(0, nrow(mymat)),\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\nfor (i in 3:nrow(mymat)) {\n  points(rep(i, ncol(varmat)),\n         mymat[i, ],\n         pch = 19,\n         col = rgb(0, 0, 0, alpha = 0.2))\n}\n\n# True population variance is ~ 400.\nabline(h = var.p(pop),\n       col = rgb(0, 0, 1, alpha = 0.5),\n       lwd = 3)\n\n# Compute the mean of sample variance at each sample size\n# and add it to the plot.\nlines(2:popsize, rowMeans(varmat),\n      col = 'orange', lwd = 3)\n\n# Add a legend\nlegend(400, 1500, \n       legend=c(\"True population variance\",\n                \"Means of sample variance\"),\n       col=c(rgb(0, 0, 1, alpha = 0.5), \"orange\"), \n       lty=1, lwd=3, box.lty=0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/sample_variance_vs_sample_size-1.png){width=1800}\n:::\n:::\n\n\nPretty crazy! The variation in sample variance is tremendous at small sample\nsizes. But the mean of this variation (orange) is basically identical to the\ntrue population variance (blue).\n\nLet's figure out at what point the variance of sample variances seem to become\nreliable. Since we know this happens at small sample sizes, we'll just plot\ncases where sample size varies from 1 to 100 to get a more refined view of the\ndata.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a function to calculate the variances of sampled \n# variance across all the replicates.\nRowVar <- function(x) {\n  rowSums((x - rowMeans(x))^2)/(dim(x)[2] - 1)\n}\n\n# Variance of sample variances at each sample size\nRowVar(varmat)->varz\n\n# Plot of variance of variance at each sample size\n# Again, this is only for sample size <= 100.\nplot(\n  varz[1:(length(pop) / 10)],\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'variance of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/mean_of_sample_variance-1.png){width=1500}\n:::\n:::\n\n\nThis trend reminds me of what we see in scree plots when conducting PCA or in\nelbow plots when trying to determine the optimal number of clusters. The\ndifficulty in applying those methods is that there isn't an underlying\ncovariance structure here (at least one that I can think of) that we'd be able\nto tease apart.\n\nFortunately, there is a package called `changepoint` that finds \"changepoints\"\nin series of data (based on shifts in either values or variance). Let's\nimplement the `changepoint::cpt.var()` function to identify a potential point\nwhere sample variances seem to stabilize.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"changepoint\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe following package(s) will be installed:\n- changepoint [2.2.4]\nThese packages will be installed into \"~/Library/CloudStorage/OneDrive-UBC/github_repos/vbaliga.github.io/renv/library/R-4.4/aarch64-apple-darwin20\".\n\n# Installing packages --------------------------------------------------------\n- Installing changepoint ...                    OK [linked from cache]\nSuccessfully installed 1 package in 3.5 milliseconds.\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(changepoint)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: zoo\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'zoo'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSuccessfully loaded changepoint package version 2.2.4\n See NEWS for details of changes.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot again\nplot(\n  varz,\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.2),\n  xlab = 'sample size',\n  ylab = 'variance of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n\n# At what sample size do we see stability?\nabline(v = cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n       col = rgb(1, 0, 0, alpha = 0.8), lty=2)\ntext(\n  x = cpt.var(varz[1:(length(varz) - 1)])@cpts[1] + 5,\n  y = 0.5 * varz[1],\n  pos = 4,\n  paste(cpt.var(varz[1:(length(varz)-1)])@cpts[1],\n        \"samples\")\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/changepoint-1.png){width=1500}\n:::\n:::\n\n\nThe vertical red line shows the sample size after which the variance of sample\nvariance tends to be relatively low.\n\n## Can we find general patterns?\n\nAt what point is sample size large enough to trust its estimation of the true\nvariance? Let's first see if it depends on the parent population's actual\nvariance.\n\nWe'll create a few other examples and see if we can find common patterns. We'll\nfix population means at 0, population sizes to be 1000 but vary standard\ndeviations (and therefore variance) widely.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean = 0\nreps = 1000\n\n# Specify our SDs and set popsize to 1000 in each case.\nparams <- expand.grid(SD = c(0.1, 0.5, 1, 2, 5,\n                             10, 50, 100),\n                      popsize = 1000)\n\n# This function takes all the steps we did in the \n# previous analysis and function-izes it.\nvarSamplr <- function(SD, popsize) {\n  pop <- rnorm(popsize, mean, SD)\n  Ns <- seq(1, popsize, 1)\n  \n  mymat = matrix(nrow = length(Ns), ncol = reps)\n  for (i in 1:dim(mymat)[1])\n  {\n    for (j in 1:dim(mymat)[2])\n    {\n      mymat[i, j] = var(sample(pop, Ns[i]))\n    }\n  }\n  rownames(mymat) <- seq(1, length(Ns))\n  mymat[-1, ] -> varmat\n  RowVar(varmat)->varz\n  \n  plot(\n    varz,\n    pch = 19,\n    col = rgb(0, 0, 0, alpha = 0.2),\n    xlab = 'sample size',\n    ylab = 'variance of sample variance',\n    tck = 0.02,\n    bty = \"n\",\n    main = paste(\n      \"N = \",\n      popsize,\n      \"; \",\n      \"SD = \",\n      SD,\n      \"\\nrelative stability at \",\n      cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n      \" samples\",\n      sep = \"\")\n  )\n\n  # At what sample size do we see stability?\n  abline(\n    v = cpt.var(varz[1:(length(varz) - 1)])@cpts[1],\n    col = rgb(1, 0, 0, alpha = 0.8),\n    lty = 2\n  )\n}\n\n# Organize so we can multi-plot\npar(mfrow = c(4, 2))\n\n# Run. This will take some time.\nfor (i in 1:nrow(params)) {\n  print(i)\n  varSamplr(params[i, 1], params[i, 2])\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/variance_of_sample_variance_vs_pop_variance-1.png){width=2100}\n:::\n:::\n\n\nPretty interesting! Although the standard deviation varies widely across these\ndata sets (from 0.1 to 100), taking samples of size 1 through \\~ 46 leaves us\nvulnerable to the dangers of the left side of the curve. So we're seeing that\nsamples of \\< 4-5% of the true population size are relatively unreliable.\n\nOf course, the `changepoint` metric does also seem a little conservative. It\nmight be worthwhile thinking of another way to find the point of relative\nstability.\n\n## Does population size matter?\n\nOne more thing I'd like to determine is if our results so far stem from fixing\nthe population size at 1000. So, we'll repeat this but instead of varying\nstandard deviation, we'll vary population size.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean = 0\nreps = 1000\n\n# This time SD is set to 1 and popsize varies\nparams <- expand.grid(SD = 1,\n                      popsize = c(50, 100, 200, 500,\n                                  1000, 2000, 3500,\n                                  5000))\n\n# Organize so we can multi-plot\npar(mfrow = c(4, 2))\n\n# Run. This will take some time.\nfor (i in 1:nrow(params)) {\n  print(i)\n  varSamplr(params[i, 1], params[i, 2])\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/sample_variance_vs_pop_size-1.png){width=2100}\n:::\n:::\n\n\nSo it seems that as true population size increases, so too does the location of\nthe changepoint. Let's plot this more explicitly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npops <- c(50, 100, 200, 500, 1000, 2000, 3500, 5000)\ncps <- c(5, 7, 13, 25, 46, 79, 130, 172)\n\nplot(\n  pops,\n  cps,\n  pch = 19,\n  col = rgb(0, 0, 0, alpha = 0.8),\n  xlab = 'population size',\n  ylab = 'changepoint of sample variance',\n  tck = 0.02,\n  bty = \"n\"\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/changepoint_vs_pop_size-1.png){width=1500}\n:::\n:::\n\n\nIndeed it seems there is a direct (log-linear?) relationship. I'm sure this is\ncovered by theory - perhaps somehow by the law of large numbers or the CTL. One\nhunch I have is that as population size decreases, our distributions get farther\naway from an ideal, infinitely-sized population.\n\nIn any case, the shape of the curve is pretty consistent across all these\nempirical trials. We can confidently conclude that we should not trust sample\nvariance at low sample sizes. What remains to be seen is how \"small\" is too\nsmall\n\nThat's all!\n\n🐢\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}